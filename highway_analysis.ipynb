{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfQypVAsVrdI"
      },
      "source": [
        "# Configurações Globais"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ypXk-zO0Hv3",
        "outputId": "b6df5a00-4c0d-4e79-e1b3-fa935e466bf2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import duckdb\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "files_to_analyze = [\n",
        "    'data/receipts-000000000000.csv',\n",
        "    'data/items-000000000000.csv',\n",
        "    'data/payments-000000000000.csv',\n",
        "    'data/discounts-000000000000.csv',\n",
        "    'data/torque.csv'\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKumVJwv3gAk"
      },
      "source": [
        "# Análise Exploratória de Dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0YssA-qVpHd",
        "outputId": "51b303c3-ad8c-4293-f39d-6395ba363b08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Conexão com DuckDB ok!\n",
            "\n",
            "\n",
            "==================== Análise do Arquivo: data/receipts-000000000000.csv ====================\n",
            "\n",
            "[1] Head dos Dados:\n",
            "                             identifier             shop_id  \\\n",
            "0  576f1b6e-e971-11ee-9aa3-0242ac1c000c  highway-praca-ekin   \n",
            "1  576f0ba6-e971-11ee-9aa3-0242ac1c000c  highway-praca-ekin   \n",
            "2  576ed2e4-e971-11ee-9aa3-0242ac1c000c  highway-praca-ekin   \n",
            "\n",
            "            timestamp  receipt_number  total_value  delivery  canceled  staff  \\\n",
            "0 2024-01-01 22:05:11               8         37.5     False     False  False   \n",
            "1 2024-01-01 23:35:35              13         49.5     False     False  False   \n",
            "2 2024-01-01 21:43:00               6         23.0     False     False  False   \n",
            "\n",
            "  operation_date  pdv  fee  change           date_time  totem  \n",
            "0     2024-01-01    1    0     0.0 2024-01-01 19:05:11  False  \n",
            "1     2024-01-01    1    0     0.0 2024-01-01 20:35:35  False  \n",
            "2     2024-01-01    1    0     0.0 2024-01-01 18:43:00  False  \n",
            "\n",
            "[2] Estrutura da Tabela:\n",
            "       column_name column_type null   key default extra\n",
            "0       identifier     VARCHAR  YES  None    None  None\n",
            "1          shop_id     VARCHAR  YES  None    None  None\n",
            "2        timestamp   TIMESTAMP  YES  None    None  None\n",
            "3   receipt_number      BIGINT  YES  None    None  None\n",
            "4      total_value      DOUBLE  YES  None    None  None\n",
            "5         delivery     BOOLEAN  YES  None    None  None\n",
            "6         canceled     BOOLEAN  YES  None    None  None\n",
            "7            staff     BOOLEAN  YES  None    None  None\n",
            "8   operation_date        DATE  YES  None    None  None\n",
            "9              pdv      BIGINT  YES  None    None  None\n",
            "10             fee      BIGINT  YES  None    None  None\n",
            "11          change      DOUBLE  YES  None    None  None\n",
            "12       date_time   TIMESTAMP  YES  None    None  None\n",
            "13           totem     BOOLEAN  YES  None    None  None\n",
            "\n",
            "[3] Quantidade de Valores Nulos por Coluna:\n",
            "   identifier_nulls  shop_id_nulls  timestamp_nulls  receipt_number_nulls  \\\n",
            "0                 0              0                0                     0   \n",
            "\n",
            "   total_value_nulls  delivery_nulls  canceled_nulls  staff_nulls  \\\n",
            "0                  0               0               0            0   \n",
            "\n",
            "   operation_date_nulls  pdv_nulls  fee_nulls  change_nulls  date_time_nulls  \\\n",
            "0                     0          0          0             0                0   \n",
            "\n",
            "   totem_nulls  \n",
            "0            0  \n",
            "\n",
            "\n",
            "==================== Análise do Arquivo: data/items-000000000000.csv ====================\n",
            "\n",
            "[1] Head dos Dados:\n",
            "                             identifier                   name  quantity  \\\n",
            "0  5658dfcc-5d78-4360-9568-74be2b85f91f             cafe longo         1   \n",
            "1  0bb6e336-3366-4012-89cf-cc8c5fc5cf10     db churrasco 15 cm         1   \n",
            "2  dd68f5fc-ad60-43f3-a946-f63a29ef1bc4  30 cm frango teriyaki         1   \n",
            "\n",
            "   value  total_value  canceled                 fk_receipt_identifier  \\\n",
            "0    0.0          0.0      True  a7d04cc4-ea2d-11ee-8390-0242ac1c000c   \n",
            "1    6.5          6.5     False  a7d01f42-ea2d-11ee-8390-0242ac1c000c   \n",
            "2   42.0         42.0     False  a7d05d18-ea2d-11ee-8390-0242ac1c000c   \n",
            "\n",
            "            date_time operation_date  \n",
            "0 2024-02-23 16:02:24     2024-02-23  \n",
            "1 2024-02-23 19:49:53     2024-02-23  \n",
            "2 2024-02-23 15:04:06     2024-02-23  \n",
            "\n",
            "[2] Estrutura da Tabela:\n",
            "             column_name column_type null   key default extra\n",
            "0             identifier     VARCHAR  YES  None    None  None\n",
            "1                   name     VARCHAR  YES  None    None  None\n",
            "2               quantity      BIGINT  YES  None    None  None\n",
            "3                  value      DOUBLE  YES  None    None  None\n",
            "4            total_value      DOUBLE  YES  None    None  None\n",
            "5               canceled     BOOLEAN  YES  None    None  None\n",
            "6  fk_receipt_identifier     VARCHAR  YES  None    None  None\n",
            "7              date_time   TIMESTAMP  YES  None    None  None\n",
            "8         operation_date        DATE  YES  None    None  None\n",
            "\n",
            "[3] Quantidade de Valores Nulos por Coluna:\n",
            "   identifier_nulls  name_nulls  quantity_nulls  value_nulls  \\\n",
            "0                 0           0               0            0   \n",
            "\n",
            "   total_value_nulls  canceled_nulls  fk_receipt_identifier_nulls  \\\n",
            "0                  0               0                            0   \n",
            "\n",
            "   date_time_nulls  operation_date_nulls  \n",
            "0                0                     0  \n",
            "\n",
            "\n",
            "==================== Análise do Arquivo: data/payments-000000000000.csv ====================\n",
            "\n",
            "[1] Head dos Dados:\n",
            "                             identifier    method  value  \\\n",
            "0  3cbef2b4-8d14-4ddb-b3a3-ebb2a6824064  DINHEIRO  160.0   \n",
            "1  f7afa29b-0748-454f-bf78-39a9cbed7642  DINHEIRO   50.0   \n",
            "2  9d698ae4-7dfc-4cfd-a396-5f7b4bf99157  DINHEIRO   50.0   \n",
            "\n",
            "                  fk_receipt_identifier           date_time operation_date  \n",
            "0  a7d00bce-ea2d-11ee-8390-0242ac1c000c 2024-02-23 20:50:45     2024-02-23  \n",
            "1  a7d00d18-ea2d-11ee-8390-0242ac1c000c 2024-02-23 20:47:03     2024-02-23  \n",
            "2  a7d06862-ea2d-11ee-8390-0242ac1c000c 2024-02-23 13:34:19     2024-02-23  \n",
            "\n",
            "[2] Estrutura da Tabela:\n",
            "             column_name column_type null   key default extra\n",
            "0             identifier     VARCHAR  YES  None    None  None\n",
            "1                 method     VARCHAR  YES  None    None  None\n",
            "2                  value      DOUBLE  YES  None    None  None\n",
            "3  fk_receipt_identifier     VARCHAR  YES  None    None  None\n",
            "4              date_time   TIMESTAMP  YES  None    None  None\n",
            "5         operation_date        DATE  YES  None    None  None\n",
            "\n",
            "[3] Quantidade de Valores Nulos por Coluna:\n",
            "   identifier_nulls  method_nulls  value_nulls  fk_receipt_identifier_nulls  \\\n",
            "0                 0             0            0                            0   \n",
            "\n",
            "   date_time_nulls  operation_date_nulls  \n",
            "0                0                     0  \n",
            "\n",
            "\n",
            "==================== Análise do Arquivo: data/discounts-000000000000.csv ====================\n",
            "\n",
            "[1] Head dos Dados:\n",
            "                             identifier                           name  total  \\\n",
            "0  d316cb13-63be-4952-a8ae-fb050bccb606  combo com cookie por 12 reais    2.0   \n",
            "1  26516995-3baf-415f-b350-5a707b8e604d  combo com cookie por 12 reais    2.0   \n",
            "2  14aa04d2-bf67-4d53-b027-684f982b3a00   combo com chips por 12 reais    3.0   \n",
            "\n",
            "   canceled  quantity                 fk_receipt_identifier  \\\n",
            "0     False         1  a7d08504-ea2d-11ee-8390-0242ac1c000c   \n",
            "1     False         1  a7cff80a-ea2d-11ee-8390-0242ac1c000c   \n",
            "2     False         1  a7d07a78-ea2d-11ee-8390-0242ac1c000c   \n",
            "\n",
            "            date_time operation_date  \n",
            "0 2024-02-23 12:01:01     2024-02-23  \n",
            "1 2024-02-23 22:00:21     2024-02-23  \n",
            "2 2024-02-23 12:51:12     2024-02-23  \n",
            "\n",
            "[2] Estrutura da Tabela:\n",
            "             column_name column_type null   key default extra\n",
            "0             identifier     VARCHAR  YES  None    None  None\n",
            "1                   name     VARCHAR  YES  None    None  None\n",
            "2                  total      DOUBLE  YES  None    None  None\n",
            "3               canceled     BOOLEAN  YES  None    None  None\n",
            "4               quantity      BIGINT  YES  None    None  None\n",
            "5  fk_receipt_identifier     VARCHAR  YES  None    None  None\n",
            "6              date_time   TIMESTAMP  YES  None    None  None\n",
            "7         operation_date        DATE  YES  None    None  None\n",
            "\n",
            "[3] Quantidade de Valores Nulos por Coluna:\n",
            "   identifier_nulls  name_nulls  total_nulls  canceled_nulls  quantity_nulls  \\\n",
            "0                 0           0            0               0            2252   \n",
            "\n",
            "   fk_receipt_identifier_nulls  date_time_nulls  operation_date_nulls  \n",
            "0                            0                0                     0  \n",
            "\n",
            "\n",
            "==================== Análise do Arquivo: data/torque.csv ====================\n",
            "\n",
            "[1] Head dos Dados:\n",
            "                        shop_id operation_date  net_torque  \\\n",
            "0            highway-praca-ekin     2024-01-01   46.261290   \n",
            "1  highway-avenida-nova-balanca     2024-01-02   50.850467   \n",
            "2            highway-praca-ekin     2024-01-02   46.874242   \n",
            "\n",
            "   net_torque_delivery  net_torque_in_store  \n",
            "0            56.896296            38.057143  \n",
            "1            47.333333            51.294737  \n",
            "2            51.566667            46.650794  \n",
            "\n",
            "[2] Estrutura da Tabela:\n",
            "           column_name column_type null   key default extra\n",
            "0              shop_id     VARCHAR  YES  None    None  None\n",
            "1       operation_date        DATE  YES  None    None  None\n",
            "2           net_torque      DOUBLE  YES  None    None  None\n",
            "3  net_torque_delivery      DOUBLE  YES  None    None  None\n",
            "4  net_torque_in_store      DOUBLE  YES  None    None  None\n",
            "\n",
            "[3] Quantidade de Valores Nulos por Coluna:\n",
            "   shop_id_nulls  operation_date_nulls  net_torque_nulls  \\\n",
            "0              0                     0                 0   \n",
            "\n",
            "   net_torque_delivery_nulls  net_torque_in_store_nulls  \n",
            "0                        961                          0  \n",
            "\n",
            "[4a] Quantidade de Recibos por Loja:\n",
            "                        shop_id  total_recibos\n",
            "0     highway-rua-bens-perdidos          44273\n",
            "1       highway-adidas-shopping          39532\n",
            "2            highway-praca-ekin          36243\n",
            "3  highway-avenida-nova-balanca          35595\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    con = duckdb.connect(database=':memory:', read_only=False)\n",
        "    print(\"Conexão com DuckDB ok!\")\n",
        "\n",
        "    for file_name in files_to_analyze:\n",
        "        print(f\"\\n\\n{'='*20} Análise do Arquivo: {file_name} {'='*20}\")\n",
        "\n",
        "        if 'items-000000000000.csv' in file_name:\n",
        "            read_command = f\"read_csv_auto('{file_name}', quote='\\\"')\"\n",
        "        else:\n",
        "            read_command = f\"read_csv_auto('{file_name}')\"\n",
        "\n",
        "        try:\n",
        "            print(\"\\n[1] Head dos Dados:\")\n",
        "            print(con.execute(f\"SELECT * FROM {read_command} LIMIT 3;\").fetchdf())\n",
        "\n",
        "            print(\"\\n[2] Estrutura da Tabela:\")\n",
        "            df_info = con.execute(f\"DESCRIBE SELECT * FROM {read_command};\").fetchdf()\n",
        "            print(df_info)\n",
        "\n",
        "            print(\"\\n[3] Quantidade de Valores Nulos por Coluna:\")\n",
        "            null_counts_sql = [f'COUNT(*) - COUNT(\"{col}\") AS \"{col}_nulls\"' for col in df_info['column_name']]\n",
        "            query_nulls = f\"SELECT {', '.join(null_counts_sql)} FROM {read_command};\"\n",
        "            print(con.execute(query_nulls).fetchdf())\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Erro ao processar o arquivo {file_name}: {e}\")\n",
        "            continue\n",
        "\n",
        "    print(\"\\n[4a] Quantidade de Recibos por Loja:\")\n",
        "    query_receipts_count = \"\"\"\n",
        "        SELECT\n",
        "            shop_id,\n",
        "            COUNT(identifier) as total_recibos\n",
        "        FROM read_csv_auto('data/receipts-000000000000.csv')\n",
        "        GROUP BY shop_id\n",
        "        ORDER BY total_recibos DESC;\n",
        "    \"\"\"\n",
        "    print(con.execute(query_receipts_count).fetchdf())\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Erro geral na célula de Análise Exploratória: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKD9yD4rN7LA"
      },
      "source": [
        "# Transformação dos Dados e Construção do ISF (Índice de Saúde Financeira)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2T_EMQ-N3o5",
        "outputId": "0ac926e1-9870-424e-8231-78e276f81ca1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Pré-visualização dos dados a serem exportados:\n",
            "  operation_date                  shop_id        isf  net_revenue  net_torque  \\\n",
            "0     2024-02-23  highway-adidas-shopping  54.047074      5877.50   52.013274   \n",
            "1     2024-02-24  highway-adidas-shopping  56.243288      6026.50   52.864035   \n",
            "2     2024-02-25  highway-adidas-shopping  51.351134      5083.04   51.604467   \n",
            "3     2024-02-27  highway-adidas-shopping  46.621581      3389.00   50.582090   \n",
            "4     2024-02-28  highway-adidas-shopping  46.300752      3736.50   48.843137   \n",
            "\n",
            "   discount_perc  \n",
            "0       1.760653  \n",
            "1       0.738283  \n",
            "2       1.662064  \n",
            "3       0.471976  \n",
            "4       0.735786  \n"
          ]
        }
      ],
      "source": [
        "con = duckdb.connect(database=':memory:', read_only=False)\n",
        "\n",
        "try:\n",
        "    # Agrega as métricas principais por dia e por loja\n",
        "    daily_metrics_query = f\"\"\"\n",
        "    WITH receipts_daily AS (\n",
        "        -- Agrega a receita líquida e a contagem de transações por dia\n",
        "        SELECT\n",
        "            shop_id,\n",
        "            operation_date,\n",
        "            SUM(total_value + fee) AS net_revenue,\n",
        "            COUNT(identifier) AS transaction_count\n",
        "        FROM read_csv_auto('data/receipts-000000000000.csv')\n",
        "        WHERE canceled = false\n",
        "        GROUP BY shop_id, operation_date\n",
        "    ),\n",
        "    discounts_daily AS (\n",
        "        -- Agrega os descontos com a tabela de receita para obter shop_id e operation_date\n",
        "        SELECT\n",
        "            r.shop_id,\n",
        "            r.operation_date,\n",
        "            SUM(d.total) AS total_discount\n",
        "        FROM read_csv_auto('data/discounts-000000000000.csv', quote='\\\"') AS d\n",
        "        JOIN read_csv_auto('data/receipts-000000000000.csv') AS r ON d.fk_receipt_identifier = r.identifier\n",
        "        WHERE d.canceled = false AND r.canceled = false\n",
        "        GROUP BY r.shop_id, r.operation_date\n",
        "    )\n",
        "    -- Junta todas as métricas diárias\n",
        "    SELECT\n",
        "        rd.shop_id,\n",
        "        rd.operation_date,\n",
        "        rd.net_revenue,\n",
        "        rd.transaction_count,\n",
        "        COALESCE(dd.total_discount, 0) AS total_discount, -- Se não tiver desconto no dia, o valor é 0\n",
        "        t.net_torque\n",
        "    FROM receipts_daily AS rd\n",
        "    LEFT JOIN discounts_daily AS dd ON rd.shop_id = dd.shop_id AND rd.operation_date = dd.operation_date\n",
        "    JOIN read_csv_auto('data/torque.csv') AS t ON rd.shop_id = t.shop_id AND rd.operation_date = t.operation_date\n",
        "    ORDER BY rd.shop_id, rd.operation_date;\n",
        "    \"\"\"\n",
        "    df_daily_health = con.execute(daily_metrics_query).fetchdf()\n",
        "\n",
        "    # Calcular o percentual de desconto diário\n",
        "    df_daily_health['discount_perc'] = (df_daily_health['total_discount'] / (df_daily_health['net_revenue'] + 1)) * 100 # o \"+ 1\" é pra não ter divisão por zero, se a receita seja 0 em algum dia\n",
        "\n",
        "    # Normaliza as métricas usando MinMaxScaler\n",
        "    scaler = MinMaxScaler()\n",
        "    metrics_to_normalize = ['net_revenue', 'net_torque', 'discount_perc']\n",
        "\n",
        "    metrics_normalized = df_daily_health[metrics_to_normalize].copy()\n",
        "    metrics_normalized.loc[:, metrics_to_normalize] = scaler.fit_transform(metrics_normalized[metrics_to_normalize])\n",
        "\n",
        "    metrics_normalized.loc[:, 'discount_perc'] = 1 - metrics_normalized['discount_perc'] # Inverte o percentual de desconto\n",
        "\n",
        "    # Pesos de cada métrica\n",
        "    weights = {'net_revenue': 0.45, 'net_torque': 0.35, 'discount_perc': 0.20}\n",
        "\n",
        "    # Cálcula o ISF e adiciona no DF\n",
        "    df_daily_health['isf'] = (\n",
        "        metrics_normalized['net_revenue'] * weights['net_revenue'] +\n",
        "        metrics_normalized['net_torque'] * weights['net_torque'] +\n",
        "        metrics_normalized['discount_perc'] * weights['discount_perc']\n",
        "    ) * 100\n",
        "\n",
        "    # DF final para exportar\n",
        "    df_looker_export = df_daily_health[[\n",
        "        'operation_date',\n",
        "        'shop_id',\n",
        "        'isf',\n",
        "        'net_revenue',\n",
        "        'net_torque',\n",
        "        'discount_perc'\n",
        "    ]].copy()\n",
        "\n",
        "    # Garante que a data está no formato correto\n",
        "    df_looker_export['operation_date'] = pd.to_datetime(df_looker_export['operation_date']).dt.date\n",
        "\n",
        "    print(\"\\nPré-visualização dos dados a serem exportados:\")\n",
        "    print(df_looker_export.head())\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Erro: {e}\")\n",
        "finally:\n",
        "    con.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iB6Js1bnn4nl"
      },
      "source": [
        "# Ranking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWeXvUmogh9a",
        "outputId": "3be296ec-fe50-4de3-c768-47b4629be82e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================== Ranking de Saúde Financeira (ISF Médio) - Junho/2025 ====================\n",
            "                        shop_id  isf_medio  receita_total_mes  torque_medio  \\\n",
            "0  highway-avenida-nova-balanca  56.921065          103113.67     68.858865   \n",
            "1       highway-adidas-shopping  55.216086          127783.70     61.064379   \n",
            "2     highway-rua-bens-perdidos  54.584016          100043.93     65.876105   \n",
            "3            highway-praca-ekin  50.299590           76473.06     60.255156   \n",
            "\n",
            "   desconto_perc_medio  \n",
            "0             2.009104  \n",
            "1             1.362024  \n",
            "2             2.068642  \n",
            "3             1.842762  \n"
          ]
        }
      ],
      "source": [
        "df_looker_export['operation_date'] = pd.to_datetime(df_looker_export['operation_date'])\n",
        "\n",
        "# Filtra os dados para apenas o mês de Junho de 2025\n",
        "df_junho_2025 = df_looker_export[(df_looker_export['operation_date'].dt.month == 6) & (df_looker_export['operation_date'].dt.year == 2025)].copy()\n",
        "\n",
        "if df_junho_2025.empty:\n",
        "    print(\"\\nNão foram encontrados dados para o mês de Junho de 2025.\")\n",
        "    print(\"Por favor, verifique o intervalo de datas dos seus arquivos de dados.\")\n",
        "else:\n",
        "    # Agrupar por loja e calcular a média do ISF e de outras métricas para o mês\n",
        "    ranking_junho = df_junho_2025.groupby('shop_id').agg(\n",
        "        isf_medio=('isf', 'mean'),\n",
        "        receita_total_mes=('net_revenue', 'sum'),\n",
        "        torque_medio=('net_torque', 'mean'),\n",
        "        desconto_perc_medio=('discount_perc', 'mean')\n",
        "    ).reset_index()\n",
        "\n",
        "    # Ordenar o ranking pelo ISF médio, do maior para o menor\n",
        "    ranking_junho_final = ranking_junho.sort_values(by='isf_medio', ascending=False).reset_index(drop=True)\n",
        "\n",
        "    print(f\"\\n{'='*20} Ranking de Saúde Financeira (ISF Médio) - Junho/2025 {'='*20}\")\n",
        "    print(ranking_junho_final)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76gln7t7hBhK",
        "outputId": "761d79a5-cd5b-4b66-d300-06387ecfb991"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================== Ranking de Saúde Financeira (ISF Médio) - 2025 ====================\n",
            "                        shop_id  isf_medio  receita_total_mes  torque_medio  \\\n",
            "0       highway-adidas-shopping  54.755490          733218.32     60.993903   \n",
            "1     highway-rua-bens-perdidos  52.762191          597368.16     62.707770   \n",
            "2  highway-avenida-nova-balanca  52.287645          459278.54     65.319818   \n",
            "3            highway-praca-ekin  48.965403          535562.81     58.446373   \n",
            "\n",
            "   desconto_perc_medio  \n",
            "0             1.203669  \n",
            "1             2.024049  \n",
            "2             1.647298  \n",
            "3             1.935428  \n"
          ]
        }
      ],
      "source": [
        "df_looker_export['operation_date'] = pd.to_datetime(df_looker_export['operation_date'])\n",
        "\n",
        "# Filtra os dados para apenas o ano de 2025\n",
        "df_2025 = df_looker_export[(df_looker_export['operation_date'].dt.year == 2025)].copy()\n",
        "\n",
        "if df_2025.empty:\n",
        "    print(\"\\nNão foram encontrados dados para o ano de 2025.\")\n",
        "    print(\"Por favor, verifique o intervalo de datas dos seus arquivos de dados.\")\n",
        "else:\n",
        "    # Agrupar por loja e calcular a média do ISF e de outras métricas para o mês\n",
        "    ranking_2025 = df_2025.groupby('shop_id').agg(\n",
        "        isf_medio=('isf', 'mean'),\n",
        "        receita_total_mes=('net_revenue', 'sum'),\n",
        "        torque_medio=('net_torque', 'mean'),\n",
        "        desconto_perc_medio=('discount_perc', 'mean')\n",
        "    ).reset_index()\n",
        "\n",
        "    # Ordenar o ranking pelo ISF médio, do maior para o menor\n",
        "    ranking_2025_final = ranking_2025.sort_values(by='isf_medio', ascending=False).reset_index(drop=True)\n",
        "\n",
        "    print(f\"\\n{'='*20} Ranking de Saúde Financeira (ISF Médio) - 2025 {'='*20}\")\n",
        "    print(ranking_2025_final)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSwTDGiEcVNp"
      },
      "source": [
        "# Exportação para o Looker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vlmXmCycXrC",
        "outputId": "1a116fc7-0c55-4457-d10f-c930231ac436"
      },
      "outputs": [],
      "source": [
        "output_filename = 'daily_financial_health.csv'\n",
        "df_looker_export.to_csv(output_filename, index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "YfQypVAsVrdI",
        "QKumVJwv3gAk",
        "DKD9yD4rN7LA"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
